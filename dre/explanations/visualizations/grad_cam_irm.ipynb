{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdb import Restart\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data\n",
    "import os\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "import collections\n",
    "import json\n",
    "import random\n",
    "import time\n",
    "import uuid\n",
    "\n",
    "sys.path.append('../../../')\n",
    "\n",
    "import numpy as np\n",
    "import PIL\n",
    "\n",
    "from domainbed import datasets\n",
    "from domainbed import hparams_registry\n",
    "from domainbed import algorithms\n",
    "from domainbed.lib import misc\n",
    "from domainbed.lib.fast_data_loader import InfiniteDataLoader, FastDataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "import matplotlib as mpl\n",
    "from captum.attr import LayerGradCam\n",
    "\n",
    "sys.path.append('../../')\n",
    "from datasets import make_dataset\n",
    "from mixuploss import MixupLoss\n",
    "from networks import ResNet\n",
    "\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='Domain generalization')\n",
    "parser.add_argument('--data_dir', type=str)\n",
    "parser.add_argument('--dataset', type=str, default=\"RotatedMNIST\")\n",
    "parser.add_argument('--algorithm', type=str, default=\"ERM\")\n",
    "parser.add_argument('--task', type=str, default=\"domain_generalization\",\n",
    "    choices=[\"domain_generalization\", \"domain_adaptation\"])\n",
    "parser.add_argument('--hparams', type=str,\n",
    "    help='JSON-serialized hparams dict')\n",
    "parser.add_argument('--hparams_seed', type=int, default=0,\n",
    "    help='Seed for random hparams (0 means \"default hparams\")')\n",
    "parser.add_argument('--trial_seed', type=int, default=0,\n",
    "    help='Trial number (used for seeding split_dataset and '\n",
    "    'random_hparams).')\n",
    "parser.add_argument('--seed', type=int, default=0,\n",
    "    help='Seed for everything else')\n",
    "parser.add_argument('--steps', type=int, default=None,\n",
    "    help='Number of steps. Default is dataset-dependent.')\n",
    "parser.add_argument('--checkpoint_freq', type=int, default=None,\n",
    "    help='Checkpoint every N steps. Default is dataset-dependent.')\n",
    "parser.add_argument('--test_envs', type=int, nargs='+', default=[0])\n",
    "parser.add_argument('--output_dir', type=str, default=\"train_output\")\n",
    "parser.add_argument('--holdout_fraction', type=float, default=0.2)\n",
    "parser.add_argument('--uda_holdout_fraction', type=float, default=0,\n",
    "    help=\"For domain adaptation, % of test to use unlabeled for training.\")\n",
    "parser.add_argument('--skip_model_save', action='store_true')\n",
    "parser.add_argument('--save_model_every_checkpoint', action='store_true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parser.parse_args(args=['--data_dir', '../../../data/',\n",
    "                               '--algorithm', 'IRM',\n",
    "                               '--dataset', 'TerraIncognita',\n",
    "                               '--test_env', '3',\n",
    "                               '--output_dir', '../visualizations/outputs/'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we ever want to implement checkpointing, just persist these values\n",
    "# every once in a while, and then load them from disk here.\n",
    "start_step = 0\n",
    "algorithm_dict = None\n",
    "\n",
    "# os.makedirs(args.output_dir, exist_ok=True)\n",
    "# sys.stdout = misc.Tee(os.path.join(args.output_dir, 'out.txt'))\n",
    "# sys.stderr = misc.Tee(os.path.join(args.output_dir, 'err.txt'))\n",
    "\n",
    "print(\"Environment:\")\n",
    "print(\"\\tPython: {}\".format(sys.version.split(\" \")[0]))\n",
    "print(\"\\tPyTorch: {}\".format(torch.__version__))\n",
    "print(\"\\tTorchvision: {}\".format(torchvision.__version__))\n",
    "print(\"\\tCUDA: {}\".format(torch.version.cuda))\n",
    "print(\"\\tCUDNN: {}\".format(torch.backends.cudnn.version()))\n",
    "print(\"\\tNumPy: {}\".format(np.__version__))\n",
    "print(\"\\tPIL: {}\".format(PIL.__version__))\n",
    "\n",
    "print('Args:')\n",
    "for k, v in sorted(vars(args).items()):\n",
    "    print('\\t{}: {}'.format(k, v))\n",
    "\n",
    "if args.hparams_seed == 0:\n",
    "    hparams = hparams_registry.default_hparams(args.algorithm, args.dataset)\n",
    "else:\n",
    "    hparams = hparams_registry.random_hparams(args.algorithm, args.dataset,\n",
    "        misc.seed_hash(args.hparams_seed, args.trial_seed))\n",
    "if args.hparams:\n",
    "    hparams.update(json.loads(args.hparams))\n",
    "\n",
    "print('HParams:')\n",
    "for k, v in sorted(hparams.items()):\n",
    "    print('\\t{}: {}'.format(k, v))\n",
    "\n",
    "random.seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "if args.dataset in vars(datasets):\n",
    "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
    "        args.test_envs, hparams)\n",
    "else:\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm_class = algorithms.get_algorithm_class(args.algorithm)\n",
    "algorithm = algorithm_class(dataset.input_shape, dataset.num_classes,\n",
    "    len(dataset) - len(args.test_envs), hparams)\n",
    "\n",
    "if algorithm_dict is not None:\n",
    "    algorithm.load_state_dict(algorithm_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('../../../domainbed/train_output/IRM/best_model.pkl')\n",
    "algorithm.load_state_dict(checkpoint['model_dict'])\n",
    "net_base = algorithm.network.to(device)\n",
    "net_base.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_ours = ResNet()\n",
    "net_ours = nn.DataParallel(net_ours)\n",
    "net_ours.module.network.fc = nn.Linear(net_ours.module.network.fc.in_features, 10)\n",
    "net_ours.load_state_dict(torch.load('../../ckpts/best_model.pth'))\n",
    "net_ours = net_ours.to(device)\n",
    "net_ours.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "            # transforms.Resize((224,224)),\n",
    "            transforms.RandomResizedCrop(224, scale=(0.7, 1.0)),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ColorJitter(0.3, 0.3, 0.3, 0.3),\n",
    "            transforms.RandomGrayscale(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "\n",
    "transform_orig = transforms.Compose([\n",
    "            transforms.Resize((224,224)),\n",
    "            transforms.ToTensor()\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset38 = torchvision.datasets.ImageFolder('../../../data/terra_incognita/location_38/', transform=transform)\n",
    "dset43 = torchvision.datasets.ImageFolder('../../../data/terra_incognita/location_43/', transform=transform)\n",
    "dset46 = torchvision.datasets.ImageFolder('../../../data/terra_incognita/location_46/', transform=transform)\n",
    "dset100 = torchvision.datasets.ImageFolder('../../../data/terra_incognita/location_100/', transform=transform)\n",
    "\n",
    "dset38_orig = torchvision.datasets.ImageFolder('../../../data/terra_incognita/location_38/', transform=transform_orig)\n",
    "dset43_orig = torchvision.datasets.ImageFolder('../../../data/terra_incognita/location_43/', transform=transform_orig)\n",
    "dset46_orig = torchvision.datasets.ImageFolder('../../../data/terra_incognita/location_46/', transform=transform_orig)\n",
    "dset100_orig = torchvision.datasets.ImageFolder('../../../data/terra_incognita/location_100/', transform=transform_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = np.sort(dset38.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 16\n",
    "imgsz = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader38 = torch.utils.data.DataLoader(dset38, batch_size=bs, shuffle=False, num_workers=8)\n",
    "loader43 = torch.utils.data.DataLoader(dset43, batch_size=bs, shuffle=False, num_workers=8)\n",
    "loader46 = torch.utils.data.DataLoader(dset46, batch_size=bs, shuffle=False, num_workers=8)\n",
    "loader100 = torch.utils.data.DataLoader(dset100, batch_size=bs, shuffle=False, num_workers=8)\n",
    "\n",
    "loader38_orig = torch.utils.data.DataLoader(dset38_orig, batch_size=bs, shuffle=False, num_workers=8)\n",
    "loader43_orig = torch.utils.data.DataLoader(dset43_orig, batch_size=bs, shuffle=False, num_workers=8)\n",
    "loader46_orig = torch.utils.data.DataLoader(dset46_orig, batch_size=bs, shuffle=False, num_workers=8)\n",
    "loader100_orig = torch.utils.data.DataLoader(dset100_orig, batch_size=bs, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_gc_base = LayerGradCam(net_base, net_base[0].network.layer4)\n",
    "layer_gc_ours = LayerGradCam(net_ours, net_ours.module.network.layer4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attr_scale(x):\n",
    "    return (x-x.min()) / (x.max()-x.min())\n",
    "\n",
    "def explain(image, image_orig, pred_base, pred_ours, count, imgsz=224, target_env='Caltech101', mode='ood'):\n",
    "    image = image.reshape(1, 3, imgsz, imgsz).to(device)\n",
    "    image_orig = image_orig.reshape(1, 3, imgsz, imgsz).to(device)\n",
    "\n",
    "    attr_base = layer_gc_base.attribute(image, target=pred_base)\n",
    "    attr_ours = layer_gc_ours.attribute(image, target=pred_ours)\n",
    "\n",
    "    attribution_base = F.interpolate(attr_base, size=imgsz, mode='bilinear').squeeze()\n",
    "    attribution_ours = F.interpolate(attr_ours, size=imgsz, mode='bilinear').squeeze()\n",
    "\n",
    "    attribution_base = attr_scale(attribution_base)\n",
    "    attribution_ours = attr_scale(attribution_ours)\n",
    "\n",
    "    cmap = mpl.cm.get_cmap('jet', 256)\n",
    "    heatmap_base = cmap(attribution_base.cpu().detach().numpy(), alpha = 0.5)\n",
    "    heatmap_ours = cmap(attribution_ours.cpu().detach().numpy(), alpha = 0.5)\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(4, 2), dpi=200)\n",
    "    # fig.suptitle('Grad-CAM', fontsize=20)\n",
    "\n",
    "    ax[0].imshow(image_orig.squeeze().cpu().detach().numpy().transpose(1, 2, 0))\n",
    "    ax[0].set_title(str(mode) + ' ' + str(target_env))\n",
    "    ax[0].axis('off')\n",
    "\n",
    "    ax[1].imshow(image_orig.squeeze().cpu().detach().numpy().transpose(1, 2, 0))\n",
    "    ax[1].set_title('IRM')\n",
    "    ax[1].axis('off')\n",
    "    ax[2].imshow(image_orig.squeeze().cpu().detach().numpy().transpose(1, 2, 0))\n",
    "    ax[2].set_title('ours')\n",
    "    ax[2].axis('off')\n",
    "\n",
    "    ax[1].imshow(heatmap_base)\n",
    "    ax[1].axis('off')\n",
    "    ax[2].imshow(heatmap_ours)\n",
    "    ax[2].axis('off')\n",
    "\n",
    "    fig.savefig('./irm/{}/{}/{}/{}_{}.jpeg'.format(mode, target_env, str(class_names[int(pred_ours.cpu().detach().numpy())]), str(count), str(class_names[int(pred_ours.cpu().detach().numpy())])))\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "it = iter(loader46)\n",
    "it_orig = iter(loader46_orig)\n",
    "\n",
    "for batch_idx in tqdm(range(len(it))):\n",
    "    inputs, targets = next(it)\n",
    "    inputs_orig, _ = next(it_orig)\n",
    "\n",
    "    inputs = inputs.to(device)\n",
    "    targets = targets.to(device)\n",
    "\n",
    "    outputs_base = net_base(inputs)\n",
    "    outputs_ours = net_ours(inputs)\n",
    "\n",
    "    preds_base = outputs_base.argmax(dim=1)\n",
    "    preds_ours = outputs_ours.argmax(dim=1)\n",
    "\n",
    "    for i in range(len(inputs)):\n",
    "        if targets[i] == 4:\n",
    "            if preds_ours[i] == targets[i]: \n",
    "                explain(inputs[i], inputs_orig[i], preds_base[i], preds_ours[i], count, target_env='L46', mode='ood')\n",
    "        count += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "02ffe4940dce8a26db6b5238b5727e42acd2513365a3fdb623eeb2bd329ab7e3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
